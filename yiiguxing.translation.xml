<application>
  <component name="AppStorage">
    <option name="newTranslationDialogHeight" value="447" />
    <option name="newTranslationDialogWidth" value="1510" />
    <option name="newTranslationDialogX" value="2" />
    <option name="newTranslationDialogY" value="526" />
    <histories>
      <item value="TIDYING" />
      <item value="packing two conceptual fields workerCount" />
      <item value="A pool that is no longer referenced in a program AND has no remaining threads will be shutdown automatically. If you would like to ensure that unreferenced pools are reclaimed even if users forget to call shutdown, then you must arrange that unused threads eventually die, by setting appropriate keep-alive times, using a lower bound of zero core threads andor setting allowCoreThreadTimeOut(boolean)." />
      <item value="manipulate" />
      <item value="saturated" />
      <item value="finite" />
      <item value="but can be more difficult to tune and control. Queue sizes and maximum pool sizes may be traded off for each other: Using large queues and small pools minimizes CPU usage, OS resources, and context-switching overhead, but can lead to artificially low throughput. If tasks frequently block (for example if they are IO bound), a system may be able to schedule time for more threads than you otherwise allow. Use of small queues generally requires larger pool sizes, which keeps CPUs busier but may encounter unacceptable scheduling overhead, which also decreases throughput." />
      <item value="transient" />
      <item value="in smoothing out transient bursts of requests" />
      <item value="in a web page server. While this style of queuing can be useful in smoothing out transient bursts of requests, it admits the possibility of unbounded work queue growth when commands continue to arrive on average faster than they can be processed." />
      <item value="This may be appropriate when each task is completely independent of others" />
      <item value="handoffs" />
      <item value="interacts" />
      <item value="If not otherwise specified" />
      <item value="prestart Core Thread" />
      <item value="reclamation" />
      <item value="programmers are urged to use the more convenient Executors factory methods" />
      <item value="extensibility" />
      <item value="adjustable" />
      <item value="To be useful across a wide range of contexts" />
      <item value="due to reduced per-task invocation overhead" />
      <item value="Thread pools address two different problems" />
      <item value="address" />
      <item value="one of possibly several pooled threads" />
      <item value="one of possibly several" />
      <item value="hould block because of policy for overtaking other waiting threads." />
      <item value="apparently First Queued Is Exclusive" />
      <item value="then invoking at least once tryAcquireShared, returning on success. Otherwise the thread is queued, possibly repeatedly blocking and unblocking, invoking tryAcquireShared until success or the thread is interrupted." />
      <item value="semantics" />
      <item value="mutual" />
      <item value="Read fields in reverse initialization order" />
      <item value="Read fields in reverse initialization order Node h = head;" />
      <item value="The correctness of this depends on head being initialized" />
      <item value="has Queued Predecessors" />
      <item value="The &quot;prev&quot; links (not used in original CLH locks), are mainly needed to handle cancellation. If a node is cancelled, its successor is (normally) relinked to a non-cancelled predecessor. For explanation of similar mechanics in the case of spin locks, see the papers by Scott and Scherer at http:www.cs.rochester.eduuscottsynchronization" />
      <item value="it takes a bit more work for nodes to determine who their successors are, in part to deal with possible cancellation due to timeouts and interrupts." />
      <item value="demarcation" />
      <item value="o enqueue into a CLH lock, you atomically splice it in as new tail. To dequeue, you just set the head field" />
      <item value="The status field does NOT control whether threads are granted locks etc though. A thread may try to acquire if it is first in the queue. But being first does not guarantee success; it only gives the right to contend. So the currently released contender thread may need to rewait." />
      <item value="The status field does NOT control whether threads are granted locks etc though. A thread may try to acquire if it is first in the queue. But being first does not guarantee success; it only gives the right to contend" />
      <item value="whether threads are granted locks etc though" />
      <item value="Each node of the queue otherwise serves as a specific-notification-style monitor holding a single waiting thread" />
      <item value="track of" />
      <item value="in the predecessor of its node" />
      <item value="tactic" />
      <item value="We instead use them for blocking synchronizers" />
      <item value="Link to the successor node that the current nodethread unparks upon release. Assigned during enqueuing, adjusted when bypassing cancelled predecessors, and nulled out (for sake of GC) when dequeued. The enq operation does not assign next field of a predecessor until after attachment, so seeing a null next field does not necessarily mean that node is at end of queue. However, if a next field appears to be null, we can scan prev's from the tail to double-check. The next field of cancelled nodes is set to point to the node itself instead of null, to make life easier for isOnSyncQueue." />
      <item value="Link to predecessor node that current nodethread relies on for checking waitStatus" />
      <item value="Link to predecessor node that current nodethread relies on for checking waitStatus. Assigned during enqueuing, and nulled out (for sake of GC) only upon dequeuing. Also, upon cancellation of a predecessor, we short-circuit while finding a non-cancelled one, which will always exist because the head node is never cancelled: A node becomes head only as a result of successful acquire. A cancelled thread never succeeds in acquiring, and a thread only cancels itself, not any other node." />
      <item value="predecessor" />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="6889" />
        <entry key="ENGLISH" value="6890" />
        <entry key="CHINESE_CLASSICAL" value="1" />
        <entry key="ALBANIAN" value="1" />
        <entry key="AZERBAIJANI" value="1" />
        <entry key="ICELANDIC" value="1" />
        <entry key="POLISH" value="1" />
        <entry key="DANISH" value="9" />
        <entry key="GERMAN" value="10" />
        <entry key="FRENCH" value="19" />
        <entry key="FINNISH" value="1" />
        <entry key="DUTCH" value="1" />
        <entry key="CATALAN" value="4" />
        <entry key="KURDISH" value="1" />
        <entry key="ROMANIAN" value="7" />
        <entry key="MALAY" value="2" />
        <entry key="NORWEGIAN" value="1" />
        <entry key="PORTUGUESE" value="8" />
        <entry key="SWEDISH" value="4" />
        <entry key="SERBIAN" value="1" />
        <entry key="SLOVAK" value="3" />
        <entry key="WELSH" value="1" />
        <entry key="SPANISH" value="13" />
        <entry key="HUNGARIAN" value="5" />
        <entry key="ITALIAN" value="5" />
      </map>
    </option>
  </component>
  <component name="Cache">
    <option name="lastTrimTime" value="1650260497359" />
  </component>
  <component name="Settings">
    <option name="baiduTranslateSettings">
      <app-key>
        <option name="appId" value="20191101000350914" />
      </app-key>
    </option>
    <option name="primaryFontFamily" value="JetBrains Mono" />
    <option name="translator" value="BAIDU" />
  </component>
</application>